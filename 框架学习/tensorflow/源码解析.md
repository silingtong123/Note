# 源码解析

#### **Tensor**

struct TTypes::tensor 其实为egien::tensor的别名

```C++
template <typename T, int NDIMS = 1, typename IndexType = Eigen::DenseIndex>
typedef Eigen::TensorMap<Eigen::Tensor<T, NDIMS, Eigen::RowMajor, IndexType>,
                        Eigen::Aligned>  Tensor;
```

DenseIndex -> std::ptrdiff_t ->貌似为long int, 第三个参数为0表示ColMajor， 为1表示RowMajor

- tensorflow tensor默认按行存储
- eigen 默认按列存储
- vector 默认按行存储
- C++ 定义了Tensor类和TensorProto类： TensorProto类适合传输，不适合计算；而Tensor类刚好相反
- tensor ---> tensorProto Tensor::AsProtoField(TensorProto* proto)
- tensorProto  ---> tensor Tensor::FromProto(const TensorProto& proto)

- - -

#### **Python如何调用C++库**

```C++
from tensorflow.python import pywrap_tensorflow as c_api  ---> c_api_util.py
from tensorflow.python.pywrap_tensorflow_internal import *  --> pywrap_tensorflow.py
pywrap_tensorflow_internal .py 通过swig构成，访问_pywrap_tensorflow_internal.so
pywrap_tensorflow_internal .py ->路径：/usr/local/lib/python3.6/site-packages/tensorflow/python

```

凡是带有gen_*的pakcage都是tensorflow编译后生成的文件， 如gen_data_flow_ops， gen_math_ops， gen_nn_ops， gen_sparse_ops---> tf_gen_op_wrapper_py, 文件后缀为对应的cc和.h文件，如data_flow_ops.cc

eg.  /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_sparse_ops.py
- - -

#### **OP 如何定义？**

TensorFlow 中每个OP都有两个重要部分，一个为OpDef，它类似于C语言的声明， 一个为*OP，为kernel计算逻辑，主要包含初始化和compute两个主要函数。

OpKernelConstruction()：主要参数OpDef，NodeDef，input_types，input_memory_types，output_types和output_memory_types

- OpDef：它类似于C语言的声明。通过OpDef对象，我们可以告诉TensorFlow当前操作的输入、输出以及参数的类型
- NodeDef：它是用来控制输入与输出的传递。在Nodef对象中，会指定当前操作的输入是由哪些操作的输出给定；当前操作是输出，又将作为哪些操作的输入
- input_types用来指定各个输入的Tensor的元素的数据类型。input_types是一个数组，其大小与输入Tensor的个数相同。
- input_memory_types用来指定各个输入的Tensor分别存放在哪个存储设备上。当前，TensorFlow只支持内存和显存两种设备
- output_types和output_memory_types指定的是输出的数据类型和存储设备

- - -

#### **OP 如何运行？**

```C++
```

- - -

#### **NodeDef 和Opdef的用处区别是啥？**

```C++
```

- - -

### **DeepRec PRMalloc**

- AllocStats： 记录每次申请内存时的状态：begin,end,size
- AllocBlock:  
  - 主要成员std::vector<AllocStats*> stats_;
  - CanInsert(AllocStats* alloc_stats) -> 插入的stat和已有的stats_成员无交集
- VirtualAllocBlock：
  - 主要成员AllocBlock* internal_block_;
  - 该block的所有者为为外界所有，本类只是持有其地址（即指针）

```C++
class LifetimeBin{
  ...
  std::vector<AllocStats*> stats_;
  std::vector<AllocBlock*> blocks_;
  std::vector<VirtualAllocBlock*> virtual_blocks_;  
}

```

- TrackAllocate() -> max_alignment_= std::max<int64_t>(max_alignment_, alignment); 修改max_alignment_ 
- TrackDeallocate() -> stats_.emplace_back(stats); 将记录的stats收集起来放入stats_
- FindBlock() -> 遍历blocks_，返回第一个满足block->CanInsert(stats)== true 的block
- BestFit(LifetimePolicy* policy)  -> 遍历stats_并调用FindBlock，若找到block，则调用block->insert, 将该stat插入AllocBlock的stats_成员； 若未找到block，则调用LifetimePolicy->FindBlock, 若找到则插入stat，并根据找到的block创建新的VirtualAllocBlock， push到virtual_blocks_中; 若仍未找到，则创建AllocBlock，并在该block中插入stat，并将block加入blocks_

- - -

```C++
class LifetimePolicy{
  ...
  std::vector<LifetimeBin*> bins_;
  std::map<size_t, LifetimeBin*> large_bins_;
  mutable spin_lock large_bin_lock_;  
}

```

- TrackDeallocate() -> GetBin(index)->TrackDeallocate(alloc_stats);找到对应bin调用TrackDeallocate
- TrackAllocate() ->GetBin(index)->TrackAllocate(alignment); 找到对应bin调用TrackAllocate
- FindBlock(AllocStats* stats, size_t bindex) ->
  - 遍历bins_， 对每个bin调用FindBlock
  - 遍历large_bins_，  对每个bin调用FindBlock

- BestFit()
  - 反向遍历large_bins_， 对每个bin调用BestFit, 传递this指针
  - 反向遍历large_bins_， 对每个bin调用BestFit, 传递this指针

- LifetimePolicy() -> 构造函数， 初始化bins_，size = large_bin_index_
                                bins_[0] = 36KB， bins_[1] = 340KB bins_[i] = 32KB + ( i+1)*4KB
- GetBin(size_t index) -> 当index < large_bin_index_时，返回bins_[index] ,当index > large_bin_index_时，在large_bins_查找，找到则返回，否则创建LifetimeBin，push到large_bins_中

- - -

```C++
class MemoryPlanner {
  ...
  std::vector<LifetimePolicy*> lifetime_stats_polices_;
  TensorPoolAllocator* allocator_;
  thread::ThreadPool* thread_pool_;
}

```

- MemoryPlanner()  --> InitPolicy(),InitStepInfo(), is_stats_(false)
- InitPolicy() --> lifetime_stats_polices_添加3个元素
  - new LifetimePolicy(_4KB,_4KB_OFFSET, _32KB));
  - new LifetimePolicy(_8KB,_8KB_OFFSET, _32KB));
  - new LifetimePolicy(_16KB,_16KB_OFFSET, _32KB));
- InitStepInfo() -->获取START_STATISTIC_STEP，  STOP_STATISTIC_STEP
- StartCollect() 开始收集， 其实也做了停止收集的工作 ->CollectDone()
  - [START_STATISTIC_STEP，  STOP_STATISTIC_STEP) is_stats_ = true.
  - [STOP_STATISTIC_STEP, ]  is_stats_ = false， 并调用CollectDone
- CollectDone() -> Schedule（） 传递了一个lamda函数, 函数中调用allocator_->Init();
- Schedule() -> thread_pool_->Schedule()
- BestLifetimePolicy() -> 遍历lifetime_stats_polices_并调用BestFit(), 选择policy->TotalMem()最小的policy返回
- StopCollect () 停止收集，函数内部代码为空。
- SetAllocator() 设置TensorPoolAllocator成员
- SetThreadPool() 设置ThreadPool成员
- Cleanup() 调用lifetime_stats_polices_中所有元素的clear_up() -> 遍历lifetimepolicy中的bins_  和large_bins_元素的clear_up()--->清理所有blocks_，virtual_blocks_
- TrackAllocate() :is_stats_==true时，遍历lifetime_stats_polices_，对每个元素调用TrackAllocate()， is_stats_= false时直接返回
- TrackDeallocate()::is_stats_==true时，遍历lifetime_stats_polices_，对每个元素调用TrackDeallocate()，  is_stats_= false时直接返回

- - -

```C++
//RAII特性：
class ScopedMemoryCollector {
  ScopedMemoryCollector(){
  MemoryPlannerFactory::GetMemoryPlanner()->StartCollect();
  }

  ~ScopedMemoryCollector(){
    MemoryPlannerFactory::GetMemoryPlanner()->StopCollect();
  }
}
```

MemoryPlannerFactory::GetMemoryPlanner()为单例模式，能够根据参数得到MemoryPlanner或NullableMemoryPlanner

- - -

```C++
class TensorPoolAllocator {
  ...
  std::unique_ptr<SubAllocator> sub_allocator_;
  MemoryPlannerBase* mem_planner_;
  size_t large_bin_index_;
  std::vector<Bin*> lifetime_bins_;
  std::map<size_t, Bin*> large_lifetime_bins_;

  TensorPoolAllocator():sub_allocator_(new DefaultCPUSubAllocator),
      mem_planner_(MemoryPlannerFactory::GetMemoryPlanner()),  
  {
   .....
   mem_planner_->SetAllocator(this);
  }

  init(){
    .....
    auto  lifetime_policy = mem_planner_->BestLifetimePolicy();
  }

  AllocateRaw(size_t alignment, size_t num_bytes)(){
    ......
    SmallAlloc();
    ...
    BigAllocate(alignment, num_bytes);
    ....
    BigAllocateStatistic(alignment, num_bytes);
  }
  SmallAlloc(){
    .....
    sub_allocator_->Alloc(alignment, total) 
  }
  BigAllocate(alignment, num_bytes){
    return SetDefaultHeader();
  }
  BigAllocateStatistic(alignment, num_bytes) {
    return SetDefaultHeader();
  }

  DeallocateRaw(){
    ...
    BigDeallocate();
    ...
  }
}


```

- BestLifetimePolicy: 遍历lifetime_policy->GetLargeBins(); 创建元素Bin, push进入large_lifetime_bins_, 遍历lifetime_policy->GetBins(); 创建元素Bin, push进入lifetime_bins_
- BigAllocate:
  - inited_==false时，调用mem_planner_->TrackAllocate(alignment, total);且后续都调用sub_allocator_->Alloc(alignment, total)
  - inited_== true时，能得到Bin就 调用Bin->Allocate, ***init()后inited_== true，mem_planner_->CollectDone会调用allocator_->Init()***;
- BigAllocateStatistic: 同上，只是额外添加了一些统计信息null_bin_counter_，hit_counter_，missed_counter_
- SetDefaultHeader: 使用了placement new， 返回rar_ptr+sizeof(head_size)为起点的user_ptr
- BigDeallocate:
  - 如果inited_==false, mem_planner_->TrackDeallocate(header); 接着调用sub_allocator_->Free(ptr, num_bytes);
  - 如果inited_==true且，header->bin不为空,调用Bin->Deallocate 

- - -

```C++
class Bin{
  ... 
  Buffer buffer_;
  VirtualBuffer virtual_buffer_;
  SubAllocator* sub_allocator_;

  Allocate(size_t total, size_t header_size) {
    ...
    buffer_.Allocate();
  }

  Deallocate(){
    ...
    buffer_.Deallocate(header->raw_ptr); 
  } 

  //初始化buffer_，virtual_buffer_，sub_allocator_
  Allocate() {...} 
}

class Buffer {
  ...
  std::stack<void*> buffer_;
  void* begin_;
  void* end_;

  //申请内存空间并且将指针保存下来
  Buffer(){...}
  
  //不真正申请，而是使用以前申请好保存下来的
  Allocate(){
    ...
     ptr = buffer_.top(); 
  }

  //不真正释放，而是存放指针
  Deallocate(){
    ...
    buffer_.emplace(p);
  }
}

```
